---
title: Normalizing Flows for Conformal Regression
abstract: Conformal Prediction (CP) algorithms estimate the uncertainty of a prediction
  model by calibrating its outputs on labeled data.  The same calibration scheme usually
  applies to any model and data without modifications. The obtained prediction intervals
  are valid by construction but could be inefficient, i.e. unnecessarily big, if the
  prediction errors are not uniformly distributed over the input space. We present
  a general scheme to localize the intervals by training the calibration process.
  The standard prediction error is replaced by an optimized distance metric that depends
  explicitly on the object attributes.  Learning the optimal metric is equivalent
  to training a Normalizing Flow that acts on the joint distribution of the errors
  and the inputs.  Unlike the Error Re-weighting CP algorithm of Papadopoulos et al.
  (2008), the framework allows estimating the gap between nominal and empirical conditional
  validity. The approach is compatible with existing locally-adaptive CP strategies
  based on re-weighting the calibration samples and applies to any point-prediction
  model without retraining.
openreview: acgwLdoB3d
section: Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: colombo24a
month: 0
tex_title: Normalizing Flows for Conformal Regression
firstpage: 881
lastpage: 893
page: 881-893
order: 881
cycles: false
bibtex_author: Colombo, Nicol\`o
author:
- given: Nicol√≤
  family: Colombo
date: 2024-09-12
address:
container-title: Proceedings of the Fortieth Conference on Uncertainty in Artificial
  Intelligence
volume: '244'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 9
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v244/main/assets/colombo24a/colombo24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
