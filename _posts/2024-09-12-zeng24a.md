---
title: 'Dirichlet Continual Learning: Tackling Catastrophic Forgetting in NLP'
abstract: Catastrophic forgetting poses a significant challenge in continual learning
  (CL). In the context of Natural Language Processing, generative-based rehearsal
  CL methods have made progress in avoiding expensive retraining.  However, generating
  pseudo samples that accurately capture the task-specific distribution remains a
  daunting task.  In this paper, we propose Dirichlet Continual Learning (DCL), a
  novel generative-based rehearsal strategy designed specifically for CL.  Different
  from the conventional use of Gaussian latent variable in Conditional Variational
  Autoencoder, DCL employs the flexibility of the Dirichlet distribution to model
  the latent variable.  This allows DCL to effectively capture sentence-level features
  from previous tasks and guide the generation of pseudo samples. Additionally, we
  introduce Jensen-Shannon Knowledge Distillation, a robust logit-based knowledge
  distillation method that enhances knowledge transfer during pseudo-sample generation.  Our
  extensive experiments show that DCL outperforms state-of-the-art methods in two
  typical tasks of task-oriented dialogue systems, demonstrating its efficacy.
openreview: jve2maFPzf
section: Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zeng24a
month: 0
tex_title: 'Dirichlet Continual Learning: Tackling Catastrophic Forgetting in NLP'
firstpage: 4096
lastpage: 4108
page: 4096-4108
order: 4096
cycles: false
bibtex_author: Zeng, Min and Yang, Haiqin and Xue, Wei and Liu, Qifeng and Guo, Yike
author:
- given: Min
  family: Zeng
- given: Haiqin
  family: Yang
- given: Wei
  family: Xue
- given: Qifeng
  family: Liu
- given: Yike
  family: Guo
date: 2024-09-12
address:
container-title: Proceedings of the Fortieth Conference on Uncertainty in Artificial
  Intelligence
volume: '244'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 9
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v244/main/assets/zeng24a/zeng24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
