---
title: Optimizing Language Models for Human Preferences is a Causal Inference Problem
abstract: As large language models (LLMs) see greater use in academic and commercial
  settings, there is increasing interest in methods that allow language models to
  generate texts aligned with human preferences. In this paper, we present an initial
  exploration of language model optimization for human preferences from *direct outcome
  datasets*, where each sample consists of a text and an associated numerical outcome
  measuring the reader’s response. We first propose that language model optimization
  should be viewed as a *causal problem* to ensure that the model correctly learns
  the relationship between the text and the outcome. We formalize this causal language
  optimization problem, and we develop a method{—}*causal preference optimization*
  (CPO){—}that solves an unbiased surrogate objective for the problem. We further
  extend CPO with *doubly robust* CPO (DR-CPO), which reduces the variance of the
  surrogate objective while retaining provably strong guarantees on bias. Finally,
  we empirically demonstrate the effectiveness of (DR-)CPO in optimizing state-of-the-art
  LLMs for human preferences on direct outcome data, and we validate the robustness
  of DR-CPO under difficult confounding conditions.
openreview: VmI8qE0UK6
software: https://github.com/torylin/causal-preference-optimization
section: Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lin24a
month: 0
tex_title: Optimizing Language Models for Human Preferences is a Causal Inference
  Problem
firstpage: 2250
lastpage: 2270
page: 2250-2270
order: 2250
cycles: false
bibtex_author: Lin, Victoria and Ben-Michael, Eli and Morency, Louis-Philippe
author:
- given: Victoria
  family: Lin
- given: Eli
  family: Ben-Michael
- given: Louis-Philippe
  family: Morency
date: 2024-09-12
address:
container-title: Proceedings of the Fortieth Conference on Uncertainty in Artificial
  Intelligence
volume: '244'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 9
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v244/main/assets/lin24a/lin24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
