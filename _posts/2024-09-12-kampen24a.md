---
title: 'Towards Scalable Bayesian Transformers: Investigating stochastic subset selection
  for NLP'
abstract: Bayesian deep learning provides a framework for quantifying uncertainty.
  However, the scale of modern neural networks applied in Natural Language Processing
  (NLP) limits the usability of Bayesian methods. Subnetwork inference aims to approximate
  the posterior by selecting a stochastic parameter subset for inference, thereby
  allowing scalable posterior approximations. Determining the optimal parameter space
  for subnetwork inference is far from trivial. In this paper, we study partially
  stochastic Bayesian neural networks in the context of transformer models for NLP
  tasks for the Laplace approximation (LA) and Stochastic weight averaging - Gaussian
  (SWAG). We propose heuristics for selecting which layers to include in the stochastic
  subset. We show that norm-based selection is promising for small subsets, and random
  selection is superior for larger subsets. Moreover, we propose Sparse-KFAC (S-KFAC),
  an extension of KFAC LA, which selects dense stochastic substructures of linear
  layers based on parameter magnitudes. S-KFAC retains performance while requiring
  substantially fewer stochastic parameters and, therefore, drastically limits memory
  footprint.
openreview: ba3McobvmG
software: https://github.com/GustavAls/PartialNLP
section: Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kampen24a
month: 0
tex_title: 'Towards Scalable Bayesian Transformers: Investigating stochastic subset
  selection for NLP'
firstpage: 1842
lastpage: 1862
page: 1842-1862
order: 1842
cycles: false
bibtex_author: Kampen, Peter Johannes Tejlgaard and Als, Gustav Ragnar Stoettrup and
  Andersen, Michael Riis
author:
- given: Peter Johannes Tejlgaard
  family: Kampen
- given: Gustav Ragnar Stoettrup
  family: Als
- given: Michael Riis
  family: Andersen
date: 2024-09-12
address:
container-title: Proceedings of the Fortieth Conference on Uncertainty in Artificial
  Intelligence
volume: '244'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 9
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v244/main/assets/kampen24a/kampen24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
