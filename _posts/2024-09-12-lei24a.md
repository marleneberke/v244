---
title: On the Inductive Biases of Demographic Parity-based Fair Learning Algorithms
abstract: Fair supervised learning algorithms assigning labels with little dependence
  on a sensitive attribute have attracted great attention in the machine learning
  community. While the demographic parity (DP)  notion has been frequently used to
  measure a modelâ€™s fairness in training fair classifiers, several studies in the
  literature suggest potential impacts of enforcing DP in fair learning algorithms.
  In this work, we analytically study the effect of standard DP-based regularization
  methods on the conditional distribution of the predicted label given the sensitive
  attribute. Our analysis shows that an imbalanced training dataset with a non-uniform
  distribution of the sensitive attribute could lead to a classification rule biased
  toward the sensitive attribute outcome holding the majority of training data. To
  control such inductive biases in DP-based fair learning, we propose a sensitive
  attribute-based distributionally robust optimization (SA-DRO) method improving robustness
  against the marginal distribution of the sensitive attribute. Finally, we present
  several numerical results on the application of DP-based learning methods to standard
  centralized and distributed learning problems. The empirical findings support our
  theoretical results on the inductive biases in DP-based fair learning algorithms
  and the debiasing effects of the proposed SA-DRO method. The project code is available
  at [github.com/lh218/Fairness-IB.git](https://github.com/lh218/Fairness-IB.git).
openreview: r1t2m5IDVV
software: https://github.com/lh218/Fairness-IB.git
section: Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lei24a
month: 0
tex_title: On the Inductive Biases of Demographic Parity-based Fair Learning Algorithms
firstpage: 2205
lastpage: 2225
page: 2205-2225
order: 2205
cycles: false
bibtex_author: Lei, Haoyu and Gohari, Amin and Farnia, Farzan
author:
- given: Haoyu
  family: Lei
- given: Amin
  family: Gohari
- given: Farzan
  family: Farnia
date: 2024-09-12
address:
container-title: Proceedings of the Fortieth Conference on Uncertainty in Artificial
  Intelligence
volume: '244'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 9
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v244/main/assets/lei24a/lei24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
