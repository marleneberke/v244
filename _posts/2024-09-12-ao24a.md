---
title: 'CSS: Contrastive Semantic Similarities for Uncertainty Quantification of LLMs'
abstract: Despite the impressive capability of large language models (LLMs), knowing
  when to trust their generations remains an open challenge. The recent literature
  on uncertainty quantification of natural language generation (NLG) utilizes a conventional
  natural language inference (NLI) classifier to measure the semantic dispersion of
  LLMs responses. These studies employ logits of NLI classifier for semantic clustering
  to estimate uncertainty. However, logits represent the probability of the predicted
  class and barely contain feature information for potential clustering. Alternatively,
  CLIP (Contrastive Language{â€“}Image Pre-training) performs impressively in extracting
  image-text pair features and measuring their similarity. To extend its usability,
  we propose Contrastive Semantic Similarity, the CLIP-based feature extraction module
  to obtain similarity features for measuring uncertainty for text pairs. We apply
  this method to selective NLG, which detects and rejects unreliable generations for
  better trustworthiness of LLMs. We conduct extensive experiments with three LLMs
  on several benchmark question-answering datasets with comprehensive evaluation metrics.
  Results show that our proposed method performs better in estimating reliable responses
  of LLMs than comparable baselines.
openreview: k0Fy2SPwtc
software: https://github.com/AoShuang92/css_uq_llms
section: Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ao24a
month: 0
tex_title: 'CSS: Contrastive Semantic Similarities for Uncertainty Quantification
  of LLMs'
firstpage: 77
lastpage: 87
page: 77-87
order: 77
cycles: false
bibtex_author: Ao, Shuang and Rueger, Stefan and Siddharthan, Advaith
author:
- given: Shuang
  family: Ao
- given: Stefan
  family: Rueger
- given: Advaith
  family: Siddharthan
date: 2024-09-12
address:
container-title: Proceedings of the Fortieth Conference on Uncertainty in Artificial
  Intelligence
volume: '244'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 9
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v244/main/assets/ao24a/ao24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
