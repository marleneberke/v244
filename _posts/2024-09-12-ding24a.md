---
title: Learning to Rank for Active Learning via Multi-Task Bilevel Optimization
abstract: Active learning is a promising paradigm for reducing labeling costs by strategically
  requesting labels to improve model performance. However, existing active learning
  methods often rely on expensive acquisition functions, extensive model retraining,
  and multiple rounds of interaction with annotators. To address these limitations,
  we propose a novel approach for active learning, which aims to select batches of
  unlabeled instances through a learned surrogate model for data acquisition. A key
  challenge in this approach is to develop an acquisition function that generalizes
  well, as the history of data, which forms part of the utility function’s input,
  grows over time. Our novel algorithmic contribution is a multi-task bilevel optimization
  framework that predicts the relative utility—measured by the validation accuracy—of
  different training sets, and ensures the learned acquisition function generalizes
  effectively. For cases where validation accuracy is expensive to evaluate, we introduce
  efficient interpolation-based surrogate models to estimate the utility function,
  reducing the evaluation cost. We demonstrate the performance of our approach through
  extensive experiments on standard active classification benchmarks.
openreview: o5Iw3kN9Eg
section: Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ding24a
month: 0
tex_title: Learning to Rank for Active Learning via Multi-Task Bilevel Optimization
firstpage: 1112
lastpage: 1128
page: 1112-1128
order: 1112
cycles: false
bibtex_author: Ding, Zixin and Chen, Si and Jia, Ruoxi and Chen, Yuxin
author:
- given: Zixin
  family: Ding
- given: Si
  family: Chen
- given: Ruoxi
  family: Jia
- given: Yuxin
  family: Chen
date: 2024-09-12
address:
container-title: Proceedings of the Fortieth Conference on Uncertainty in Artificial
  Intelligence
volume: '244'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 9
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v244/main/assets/ding24a/ding24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
