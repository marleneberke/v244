---
title: Multi-layer random features and the approximation power of neural networks
abstract: A neural architecture with randomly initialized weights, in the infinite
  width limit, is equivalent to a Gaussian Random Field whose covariance function
  is the so-called Neural Network Gaussian Process kernel (NNGP). We prove that a
  reproducing kernel Hilbert space (RKHS) defined by the NNGP contains only functions
  that can be approximated by the architecture. To achieve a certain approximation
  error the required number of neurons in each layer is defined by the RKHS norm of
  the target function. Moreover, the approximation can be constructed from a supervised
  dataset by a random multi-layer representation of an input vector, together with
  training of the last layer’s weights. For a 2-layer NN and a domain equal to an
  $n-1$-dimensional sphere in ${\mathbb R}^n$, we compare the number of neurons required
  by Barron’s theorem and by the multi-layer features construction. We show that if
  eigenvalues of the integral operator of the NNGP decay slower than $k^{-n-\frac{2}{3}}$
  where $k$ is an order of an eigenvalue, then our theorem guarantees a more succinct
  neural network approximation than Barron’s theorem. We also make some computational
  experiments to verify our theoretical findings. Our experiments show that realistic
  neural networks easily learn target functions even when both theorems do not give
  any guarantees.
openreview: R6T9yA4aNg
software: https://github.com/k-nic/NNGP
section: Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: takhanov24a
month: 0
tex_title: Multi-layer random features and the approximation power of neural networks
firstpage: 3299
lastpage: 3322
page: 3299-3322
order: 3299
cycles: false
bibtex_author: Takhanov, Rustem
author:
- given: Rustem
  family: Takhanov
date: 2024-09-12
address:
container-title: Proceedings of the Fortieth Conference on Uncertainty in Artificial
  Intelligence
volume: '244'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 9
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v244/main/assets/takhanov24a/takhanov24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
