---
title: 'FedAST: Federated Asynchronous Simultaneous Training'
abstract: Federated Learning (FL) enables edge devices or clients to collaboratively
  train machine learning (ML) models without sharing their private data. Much of the
  existing work in FL focuses on efficiently learning a model for a single task. In
  this paper, we study simultaneous training of multiple FL models using a common
  set of clients. The few existing simultaneous training methods employ synchronous
  aggregation of client updates, which can cause significant delays because large
  models and/or slow clients can bottleneck the aggregation. On the other hand, a
  naive asynchronous aggregation is adversely affected by stale client updates. We
  propose FedAST, a buffered asynchronous federated simultaneous training algorithm
  that overcomes bottlenecks from slow models and adaptively allocates client resources
  across heterogeneous tasks. We provide theoretical convergence guarantees for FedAST
  for smooth non-convex objective functions. Extensive experiments over multiple real-world
  datasets demonstrate that our proposed method outperforms existing simultaneous
  FL approaches, achieving up to 46.0% reduction in time to train multiple tasks to
  completion.
openreview: yfQEtBP988
software: https://github.com/askinb/FedAST/tree/main
section: Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: askin24a
month: 0
tex_title: 'FedAST: Federated Asynchronous Simultaneous Training'
firstpage: 138
lastpage: 172
page: 138-172
order: 138
cycles: false
bibtex_author: Askin, Baris and Sharma, Pranay and Joe-Wong, Carlee and Joshi, Gauri
author:
- given: Baris
  family: Askin
- given: Pranay
  family: Sharma
- given: Carlee
  family: Joe-Wong
- given: Gauri
  family: Joshi
date: 2024-09-12
address:
container-title: Proceedings of the Fortieth Conference on Uncertainty in Artificial
  Intelligence
volume: '244'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 9
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v244/main/assets/askin24a/askin24a.pdf
extras:
- label: Supplementary PDF
  link: https://raw.githubusercontent.com/mlresearch/v244/main/assets/assets/askin24a/askin24a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
