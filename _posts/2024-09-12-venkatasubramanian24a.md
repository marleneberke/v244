---
title: Random Linear Projections Loss for Hyperplane-Based Optimization in Neural
  Networks
abstract: Advancing loss function design is pivotal for optimizing neural network
  training and performance. This work introduces Random Linear Projections (RLP) loss,
  a novel approach that enhances training efficiency by leveraging geometric relationships
  within the data. Distinct from traditional loss functions that target minimizing
  pointwise errors, RLP loss operates by minimizing the distance between sets of hyperplanes
  connecting fixed-size subsets of feature-prediction pairs and feature-label pairs.
  Our empirical evaluations, conducted across benchmark datasets and synthetic examples,
  demonstrate that neural networks trained with RLP loss outperform those trained
  with traditional loss functions, achieving improved performance with fewer data
  samples, and exhibiting greater robustness to additive noise. We provide theoretical
  analysis supporting our empirical findings.
openreview: ViuCERY1Pn
software: https://github.com/AhmedAloui1997/RandomLinearProjections
section: Papers
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: venkatasubramanian24a
month: 0
tex_title: Random Linear Projections Loss for Hyperplane-Based Optimization in Neural
  Networks
firstpage: 3425
lastpage: 3447
page: 3425-3447
order: 3425
cycles: false
bibtex_author: Venkatasubramanian, Shyam and Aloui, Ahmed and Tarokh, Vahid
author:
- given: Shyam
  family: Venkatasubramanian
- given: Ahmed
  family: Aloui
- given: Vahid
  family: Tarokh
date: 2024-09-12
address:
container-title: Proceedings of the Fortieth Conference on Uncertainty in Artificial
  Intelligence
volume: '244'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 9
  - 12
pdf: https://raw.githubusercontent.com/mlresearch/v244/main/assets/venkatasubramanian24a/venkatasubramanian24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
